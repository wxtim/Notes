{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Thoughts on Pytest\n",
    "\n",
    "## Your experience\n",
    "* Have you used unittest?\n",
    "* Have you used pytest?\n",
    "* What other testing frameworks have you used, not just in Python?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## My experience\n",
    "* I have used unittest a lot on StaGE & Improver\n",
    "* I love doctest\n",
    "* I have only come across pytest in the last week\n",
    "* I have a PR which if accepted will add pytests to Rose.\n",
    "\n",
    "<aside class=\"warning\"><font color=\"red\"><h3>I'm not an expert, but a fellow traveller sharing discoveries - I could be plain wrong, or raise points people disagree with!\n",
    "    </font></aside></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What I found on the Web:\n",
    "I'm summarizing, doesn't mean arguments necessarily convince me...\n",
    "### The web says (In Favour):\n",
    "* Produces tidier code than unittest - no requirement to subclass unittest.TestCase [1] [2] [5]\n",
    "\n",
    "* Simpler to use because it uses `assert` rather than importing asserting functions.\n",
    "\n",
    "* Failure info is often easier to read [1]\n",
    "\n",
    "* Debugging is quite nice - it's possible to drop into debug mode if a test fails. [1] [5]\n",
    "\n",
    "* Still Runs Unittests and Doctests tests anyway.\n",
    "\n",
    "* Extensions/Plugins include support for Parallelization - really important on big projects! [4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### ... and against\n",
    "* Not making tests methods of a test class make it harder for test framework to decide what to run [3]\n",
    "\n",
    "* unittest derives from xUnit and so has cross language familiarity? [1]\n",
    "\n",
    "* Not available on RHEL6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Sources\n",
    "1. https://www.slant.co/versus/9148/9149/~unittest_vs_pytest\n",
    "2. https://docs.python-guide.org/writing/tests/\n",
    "3. https://cournape.github.io/why-i-am-not-a-fan-of-pytest.html - bit ranty?\n",
    "4. https://docs.python-guide.org/writing/tests/\n",
    "5. https://docs.pytest.org/en/latest/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# Pytest - An example\n",
    "For the sake of illustrating the differences to myself I wrote some very simple code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This main function doesn't do anything\n"
     ]
    }
   ],
   "source": [
    "# %load function.py\n",
    "# A simple mathematical function on which to try different testing frameworks\n",
    "\n",
    "def square_plus_10(x):\n",
    "    \"\"\"\n",
    "    Doctest Example (Including one designed to fail)\n",
    "    >>> square_plus_10(2)\n",
    "    14\n",
    "    >>> square_plus_10(-2)\n",
    "    14\n",
    "    >>> square_plus_10(7)\n",
    "    42\n",
    "    \"\"\"\n",
    "    return (x * x) + 10\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(\"This main function doesn\\'t do anything\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "I also wrote some unittests:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import unittest\n",
    "\n",
    "from function import square_plus_10\n",
    "\n",
    "TEST_CASES = ([ 2, 14],\n",
    "              [-2, 14],\n",
    "              [ 7, \"Bowl of petunias\"])\n",
    "\n",
    "\n",
    "# Very simple unittest\n",
    "class TestSquarePlus10(unittest.TestCase):\n",
    "    def test_basic(self):\n",
    "        self.assertEqual(square_plus_10(2), 14)\n",
    "\n",
    "    def test_basic(self):\n",
    "        self.assertEqual(square_plus_10(-2), 14)\n",
    "\n",
    "    def test_basic(self):\n",
    "        self.assertEqual(square_plus_10(7), \"Bowl of petunias\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which I can run thus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F\n",
      "======================================================================\n",
      "FAIL: test_basic (tests_unittest.test_function1.TestSquarePlus10)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/net/my/home/dir/tutself_pytest/tests_unittest/test_function1.py\", line 21, in test_basic\n",
      "    self.assertEqual(square_plus_10(7), \"Bowl of petunias\")\n",
      "AssertionError: 59 != 'Bowl of petunias'\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.001s\n",
      "\n",
      "FAILED (failures=1)\n"
     ]
    }
   ],
   "source": [
    "!python3 -m unittest tests_unittest/test_function1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "\n",
    "from function import square_plus_10\n",
    "\n",
    "TEST_CASES = ([ 2, 14],\n",
    "              [-2, 14],\n",
    "              [ 7, \"Bowl of petunias\"])\n",
    "\n",
    "# Slightly More Convient\n",
    "class TestSquarePlus10_iterative_but_unhelpful(unittest.TestCase):\n",
    "    def test_basic(self):\n",
    "        for case in TEST_CASES:\n",
    "            # create a useful error message\n",
    "            msg = f\"square_plus_10({case[0]}) != {case[1]}\"\n",
    "            self.assertEqual(square_plus_10(case[0]), case[1], msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F\n",
      "======================================================================\n",
      "FAIL: test_basic (tests_unittest.test_function2.TestSquarePlus10_iterative_but_unhelpful)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/net/my/home/dir/tutself_pytest/tests_unittest/test_function2.py\", line 17, in test_basic\n",
      "    self.assertEqual(square_plus_10(case[0]), case[1], msg)\n",
      "AssertionError: 59 != 'Bowl of petunias' : square_plus_10(7) != Bowl of petunias\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.001s\n",
      "\n",
      "FAILED (failures=1)\n"
     ]
    }
   ],
   "source": [
    "!python3 -m unittest tests_unittest/test_function2~.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "\n",
    "from function import square_plus_10\n",
    "\n",
    "TEST_CASES = ([ 2, 14],\n",
    "              [-2, 14],\n",
    "              [ 7, \"Bowl of petunias\"])\n",
    "\n",
    "\n",
    "# Much nicer (from 3.5 onwards)\n",
    "class TestSquarePlus10_iterative_nicer(unittest.TestCase):\n",
    "    def test_basic(self):\n",
    "        for case in TEST_CASES:\n",
    "            with self.subTest(case):\n",
    "                self.assertEqual(square_plus_10(case[0]), case[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "FAIL: test_basic (tests_unittest.test_function3.TestSquarePlus10_iterative_nicer) [[7, 'Bowl of petunias']]\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/net/my/home/dir/tutself_pytest/tests_unittest/test_function3.py\", line 17, in test_basic\n",
      "    self.assertEqual(square_plus_10(case[0]), case[1])\n",
      "AssertionError: 59 != 'Bowl of petunias'\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.002s\n",
      "\n",
      "FAILED (failures=1)\n"
     ]
    }
   ],
   "source": [
    "!python3 -m unittest tests_unittest/test_function3.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can also run these tests using pytest, which, quelle surprise, produces the same results..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m=============================================================================================== test session starts ===============================================================================================\u001b[0m\n",
      "platform linux -- Python 3.6.6, pytest-4.2.1, py-1.7.0, pluggy-0.8.1\n",
      "rootdir: /net/my/home/dir/tutself_pytest, inifile:\n",
      "plugins: xdist-1.26.1, remotedata-0.3.1, openfiles-0.3.2, forked-1.0.2, doctestplus-0.2.0, arraydiff-0.3\n",
      "collected 3 items                                                                                                                                                                                                 \u001b[0m\n",
      "\n",
      "tests_unittest/test_function.py \u001b[31mF\u001b[0m\u001b[31mF\u001b[0m\u001b[31mF\u001b[0m\u001b[36m                                                                                                                                                                         [100%]\u001b[0m\n",
      "\n",
      "==================================================================================================== FAILURES =====================================================================================================\n",
      "\u001b[31m\u001b[1m___________________________________________________________________________________________ TestSquarePlus10.test_basic ___________________________________________________________________________________________\u001b[0m\n",
      "\n",
      "self = <test_function.TestSquarePlus10 testMethod=test_basic>\n",
      "\n",
      "\u001b[1m    def test_basic(self):\u001b[0m\n",
      "\u001b[1m>       self.assertEqual(square_plus_10(7), \"Bowl of petunias\")\u001b[0m\n",
      "\u001b[1m\u001b[31mE       AssertionError: 59 != 'Bowl of petunias'\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtests_unittest/test_function.py\u001b[0m:21: AssertionError\n",
      "\u001b[31m\u001b[1m_______________________________________________________________________________ TestSquarePlus10_iterative_but_unhelpful.test_basic _______________________________________________________________________________\u001b[0m\n",
      "\n",
      "self = <test_function.TestSquarePlus10_iterative_but_unhelpful testMethod=test_basic>\n",
      "\n",
      "\u001b[1m    def test_basic(self):\u001b[0m\n",
      "\u001b[1m        for case in TEST_CASES:\u001b[0m\n",
      "\u001b[1m            # create a useful error message\u001b[0m\n",
      "\u001b[1m            msg = f\"square_plus_10({case[0]}) != {case[1]}\"\u001b[0m\n",
      "\u001b[1m>           self.assertEqual(square_plus_10(case[0]), case[1], msg)\u001b[0m\n",
      "\u001b[1m\u001b[31mE           AssertionError: 59 != 'Bowl of petunias' : square_plus_10(7) != Bowl of petunias\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtests_unittest/test_function.py\u001b[0m:30: AssertionError\n",
      "\u001b[31m\u001b[1m___________________________________________________________________________________ TestSquarePlus10_iterative_nicer.test_basic ___________________________________________________________________________________\u001b[0m\n",
      "\n",
      "self = <test_function.TestSquarePlus10_iterative_nicer testMethod=test_basic>\n",
      "\n",
      "\u001b[1m    def test_basic(self):\u001b[0m\n",
      "\u001b[1m        for case in TEST_CASES:\u001b[0m\n",
      "\u001b[1m            with self.subTest(case):\u001b[0m\n",
      "\u001b[1m>               self.assertEqual(square_plus_10(case[0]), case[1])\u001b[0m\n",
      "\u001b[1m\u001b[31mE               AssertionError: 59 != 'Bowl of petunias'\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtests_unittest/test_function.py\u001b[0m:38: AssertionError\n",
      "\u001b[31m\u001b[1m============================================================================================ 3 failed in 0.12 seconds =============================================================================================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pytest tests_unittest/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also write a similar test in pure pytest format (which means that it won't work in unittest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import pytest\n",
    "\n",
    "from function import square_plus_10\n",
    "\n",
    "TEST_CASES = ([ 2, 14],\n",
    "              [-2, 14],\n",
    "              [ 7, \"Bowl of petunias\"])\n",
    "\n",
    "# Much nicer\n",
    "# No class required, no self required, no subTest required\n",
    "# class TestSquarePlus10_iterative_nicer(unittest.TestCase):\n",
    "def test_pure_pytest_example():\n",
    "    for case in TEST_CASES:\n",
    "        assert(square_plus_10(case[0]) == case[1])\n",
    "\n",
    "\n",
    "# Using Pytest parameterize\n",
    "@pytest.mark.parametrize(\"test_input, expected\", TEST_CASES)\n",
    "def test_pytest_with_parameterization(test_input, expected):\n",
    "    assert square_plus_10(test_input) == expected\n",
    "\n",
    "\n",
    "# Show the working of pytest.approx lest anyone ask me about\n",
    "# assertAlmostEqual\n",
    "def test_pytest_almost_equal():\n",
    "    pytest.approx(10, abs=0.1) == 9.9999\n",
    "    pytest.approx(1, rel=0.1) == 1.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m=============================================================================================== test session starts ===============================================================================================\u001b[0m\n",
      "platform linux -- Python 3.6.6, pytest-4.2.1, py-1.7.0, pluggy-0.8.1\n",
      "rootdir: /net/my/home/dir/tutself_pytest, inifile:\n",
      "plugins: xdist-1.26.1, remotedata-0.3.1, openfiles-0.3.2, forked-1.0.2, doctestplus-0.2.0, arraydiff-0.3\n",
      "collected 5 items                                                                                                                                                                                                 \u001b[0m\n",
      "\n",
      "tests_pytest/test_pytest_example.py \u001b[31mF\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[31mF\u001b[0m\u001b[32m.\u001b[0m\u001b[36m                                                                                                                                                                   [100%]\u001b[0m\n",
      "\n",
      "==================================================================================================== FAILURES =====================================================================================================\n",
      "\u001b[31m\u001b[1m____________________________________________________________________________________________ test_pure_pytest_example _____________________________________________________________________________________________\u001b[0m\n",
      "\n",
      "\u001b[1m    def test_pure_pytest_example():\u001b[0m\n",
      "\u001b[1m        for case in TEST_CASES:\u001b[0m\n",
      "\u001b[1m            # Hey look, it's just the inbuilt assert\u001b[0m\n",
      "\u001b[1m>           assert(square_plus_10(case[0]) == case[1])\u001b[0m\n",
      "\u001b[1m\u001b[31mE           AssertionError: assert 59 == 'Bowl of petunias'\u001b[0m\n",
      "\u001b[1m\u001b[31mE            +  where 59 = square_plus_10(7)\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtests_pytest/test_pytest_example.py\u001b[0m:18: AssertionError\n",
      "\u001b[31m\u001b[1m______________________________________________________________________________ test_pytest_with_parameterization[7-Bowl of petunias] ______________________________________________________________________________\u001b[0m\n",
      "\n",
      "test_input = 7, expected = 'Bowl of petunias'\n",
      "\n",
      "\u001b[1m    @pytest.mark.parametrize(\"test_input, expected\", TEST_CASES)\u001b[0m\n",
      "\u001b[1m    def test_pytest_with_parameterization(test_input, expected):\u001b[0m\n",
      "\u001b[1m>       assert square_plus_10(test_input) == expected\u001b[0m\n",
      "\u001b[1m\u001b[31mE       AssertionError: assert 59 == 'Bowl of petunias'\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +  where 59 = square_plus_10(7)\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtests_pytest/test_pytest_example.py\u001b[0m:23: AssertionError\n",
      "\u001b[31m\u001b[1m======================================================================================= 2 failed, 3 passed in 0.08 seconds ========================================================================================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest tests_pytest/test_pytest_example.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We didn't have to do any of the self.xxx stuff\n",
    "* We didn't have to have classes (although we can if it helps us organise stuff)\n",
    "* We didn't have to do much to get a useful error message."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doctests\n",
    "cooler still you can run doctests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m=============================================================================================== test session starts ===============================================================================================\u001b[0m\n",
      "platform linux -- Python 3.6.6, pytest-4.2.1, py-1.7.0, pluggy-0.8.1\n",
      "rootdir: /net/my/home/dir/tutself_pytest, inifile:\n",
      "plugins: xdist-1.26.1, remotedata-0.3.1, openfiles-0.3.2, forked-1.0.2, doctestplus-0.2.0, arraydiff-0.3\n",
      "collected 1 item                                                                                                                                                                                                  \u001b[0m\n",
      "\n",
      "function.py \u001b[31mF\u001b[0m\u001b[36m                                                                                                                                                                                               [100%]\u001b[0m\n",
      "\n",
      "==================================================================================================== FAILURES =====================================================================================================\n",
      "\u001b[31m\u001b[1m________________________________________________________________________________________ [doctest] function.square_plus_10 ________________________________________________________________________________________\u001b[0m\n",
      "004 \n",
      "005     Doctest Example (Including one designed to fail)\n",
      "006     >>> square_plus_10(2)\n",
      "007     14\n",
      "008     >>> square_plus_10(-2)\n",
      "009     14\n",
      "010     >>> square_plus_10(7)\n",
      "Expected:\n",
      "    A very surprised sperm whale\n",
      "Got:\n",
      "    59\n",
      "\n",
      "\u001b[1m\u001b[31m/net/my/home/dir/tutself_pytest/function.py\u001b[0m:10: DocTestFailure\n",
      "\u001b[31m\u001b[1m============================================================================================ 1 failed in 0.02 seconds =============================================================================================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest --doctest-modules function.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Python DeBug Compatibility\n",
    "You can even drop into the doctest in pdb mode!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m=============================================================================================== test session starts ===============================================================================================\u001b[0m\n",
      "platform linux -- Python 3.6.6, pytest-4.2.1, py-1.7.0, pluggy-0.8.1\n",
      "rootdir: /net/my/home/dir/tutself_pytest, inifile:\n",
      "plugins: xdist-1.26.1, remotedata-0.3.1, openfiles-0.3.2, forked-1.0.2, doctestplus-0.2.0, arraydiff-0.3\n",
      "collected 1 item                                                                                                                                                                                                  \u001b[0m\n",
      "\n",
      "function.py \u001b[31mF\u001b[0m\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> traceback >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "004 \n",
      "005     Doctest Example (Including one designed to fail)\n",
      "006     >>> square_plus_10(2)\n",
      "007     14\n",
      "008     >>> square_plus_10(-2)\n",
      "009     14\n",
      "010     >>> square_plus_10(7)\n",
      "Expected:\n",
      "    A very surprised sperm whale\n",
      "Got:\n",
      "    59\n",
      "\n",
      "\u001b[1m\u001b[31m/net/my/home/dir/tutself_pytest/function.py\u001b[0m:10: DocTestFailure\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> entering PDB >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "> /opt/scitools/environments/experimental/2019_02_18-1/lib/python3.6/site-packages/_pytest/doctest.py(153)report_failure()\n",
      "-> raise failure\n",
      "(Pdb) \n",
      "--KeyboardInterrupt--\n",
      "(Pdb) "
     ]
    }
   ],
   "source": [
    "!pytest --doctest-modules function.py --pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Markers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A small change to the pytests file allows us to tag tests\n",
    "```python\n",
    "@pytest.mark.pointless_tests\n",
    "def test_pytest_almost_equal():\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m=============================================================================================== test session starts ===============================================================================================\u001b[0m\n",
      "platform linux -- Python 3.6.6, pytest-4.2.1, py-1.7.0, pluggy-0.8.1\n",
      "rootdir: /net/my/home/dir/tutself_pytest, inifile:\n",
      "plugins: xdist-1.26.1, remotedata-0.3.1, openfiles-0.3.2, forked-1.0.2, doctestplus-0.2.0, arraydiff-0.3\n",
      "collected 2 items / 1 deselected / 1 selected                                                                                                                                                                     \u001b[0m\n",
      "\n",
      "tests_pytest/test_pytest_example_allgood.py \u001b[32m.\u001b[0m\u001b[36m                                                                                                                                                               [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m\u001b[1m===================================================================================== 1 passed, 1 deselected in 0.01 seconds ======================================================================================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest tests_pytest/test_pytest_example_allgood.py -m \"pointless_tests\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m=============================================================================================== test session starts ===============================================================================================\u001b[0m\n",
      "platform linux -- Python 3.6.6, pytest-4.2.1, py-1.7.0, pluggy-0.8.1\n",
      "rootdir: /net/my/home/dir/tutself_pytest, inifile:\n",
      "plugins: xdist-1.26.1, remotedata-0.3.1, openfiles-0.3.2, forked-1.0.2, doctestplus-0.2.0, arraydiff-0.3\n",
      "collected 2 items / 1 deselected / 1 selected                                                                                                                                                                     \u001b[0m\n",
      "\n",
      "tests_pytest/test_pytest_example_allgood.py \u001b[32m.\u001b[0m\u001b[36m                                                                                                                                                               [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m\u001b[1m===================================================================================== 1 passed, 1 deselected in 0.02 seconds ======================================================================================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest tests_pytest/test_pytest_example_allgood.py -m \"not pointless_tests\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or use k to get specific expression matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m=============================================================================================== test session starts ===============================================================================================\u001b[0m\n",
      "platform linux -- Python 3.6.6, pytest-4.2.1, py-1.7.0, pluggy-0.8.1\n",
      "rootdir: /net/my/home/dir/tutself_pytest, inifile:\n",
      "plugins: xdist-1.26.1, remotedata-0.3.1, openfiles-0.3.2, forked-1.0.2, doctestplus-0.2.0, arraydiff-0.3\n",
      "collected 2 items / 1 deselected / 1 selected                                                                                                                                                                     \u001b[0m\n",
      "\n",
      "tests_pytest/test_pytest_example_allgood.py \u001b[32m.\u001b[0m\u001b[36m                                                                                                                                                               [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m\u001b[1m===================================================================================== 1 passed, 1 deselected in 0.01 seconds ======================================================================================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest tests_pytest/test_pytest_example_allgood.py -k \"almost_equal\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...or select test classes or class.methods()..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m=============================================================================================== test session starts ===============================================================================================\u001b[0m\n",
      "platform linux -- Python 3.6.6, pytest-4.2.1, py-1.7.0, pluggy-0.8.1\n",
      "rootdir: /net/my/home/dir/tutself_pytest, inifile:\n",
      "plugins: xdist-1.26.1, remotedata-0.3.1, openfiles-0.3.2, forked-1.0.2, doctestplus-0.2.0, arraydiff-0.3\n",
      "collected 1 item                                                                                                                                                                                                  \u001b[0m\n",
      "\n",
      "tests_unittest/test_function3.py \u001b[31mF\u001b[0m\u001b[36m                                                                                                                                                                          [100%]\u001b[0m\n",
      "\n",
      "==================================================================================================== FAILURES =====================================================================================================\n",
      "\u001b[31m\u001b[1m___________________________________________________________________________________ TestSquarePlus10_iterative_nicer.test_basic ___________________________________________________________________________________\u001b[0m\n",
      "\n",
      "self = <test_function3.TestSquarePlus10_iterative_nicer testMethod=test_basic>\n",
      "\n",
      "\u001b[1m    def test_basic(self):\u001b[0m\n",
      "\u001b[1m        for case in TEST_CASES:\u001b[0m\n",
      "\u001b[1m            with self.subTest(case):\u001b[0m\n",
      "\u001b[1m>               self.assertEqual(square_plus_10(case[0]), case[1])\u001b[0m\n",
      "\u001b[1m\u001b[31mE               AssertionError: 59 != 'Bowl of petunias'\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtests_unittest/test_function3.py\u001b[0m:17: AssertionError\n",
      "\u001b[31m\u001b[1m============================================================================================ 1 failed in 0.07 seconds =============================================================================================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest tests_unittest/test_function3.py::TestSquarePlus10_iterative_nicer::test_basic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, rather wonderfully:\n",
    "```python\n",
    "@pytest.mark.skip(\"Some Excuse\")\n",
    "...\n",
    "@pytest.mark.skipif(some>condition, \"Another Excuse\") # Default example - test Python version\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print\n",
    "`pytest --capture=no` will cause all print() to go to sdout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pydest Xdist -\n",
    "A plugin to allow you to use multiprocessor testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m=============================================================================================== test session starts ===============================================================================================\u001b[0m\n",
      "platform linux -- Python 3.6.6, pytest-4.2.1, py-1.7.0, pluggy-0.8.1\n",
      "rootdir: /net/my/home/dir/tutself_pytest, inifile:\n",
      "plugins: xdist-1.26.1, remotedata-0.3.1, openfiles-0.3.2, forked-1.0.2, doctestplus-0.2.0, arraydiff-0.3\n",
      "gw0 [4]\u001b[0m\n",
      "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[36m                                                                                                                                                                                                        [100%]\u001b[0m\n",
      "\u001b[32m\u001b[1m============================================================================================ 4 passed in 18.93 seconds ============================================================================================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest tests_pytest/test_parallel.py -n 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m=============================================================================================== test session starts ===============================================================================================\u001b[0m\n",
      "platform linux -- Python 3.6.6, pytest-4.2.1, py-1.7.0, pluggy-0.8.1\n",
      "rootdir: /net/my/home/dir/tutself_pytest, inifile:\n",
      "plugins: xdist-1.26.1, remotedata-0.3.1, openfiles-0.3.2, forked-1.0.2, doctestplus-0.2.0, arraydiff-0.3\n",
      "gw0 [4] / gw1 [4] / gw2 [4] / gw3 [4]\u001b[0m\n",
      "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[36m                                                                                                                                                                                                        [100%]\u001b[0m\n",
      "\u001b[32m\u001b[1m============================================================================================ 4 passed in 6.66 seconds =============================================================================================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest tests_pytest/test_parallel.py -n 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "* There a lots of good reasons to use Pytest. \n",
    "* I've seen some doubts on the internet\n",
    "* But not many\n",
    "* I haven't touched on Pytest fixtures I propose adding them to the Python Guild Todo List!\n",
    "\n",
    "## Discussion Point\n",
    "1. What do people think of the web arguements?\n",
    "\n",
    "2. Should we aim to make our pytests unittest compatible, or not worry?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
