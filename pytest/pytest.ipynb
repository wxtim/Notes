{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Thoughts on Pytest\n",
    "## Coming up\n",
    "1. A brief review of what a quick web-search has to say\n",
    "2. Some trivial demos\n",
    "\n",
    "![](etc/python_exam.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Your experience\n",
    "* Have you used unittest?\n",
    "* Have you used pytest?\n",
    "* What other testing frameworks have you used, not just in Python?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## My experience\n",
    "* I have used unittest a lot on StaGE & Improver\n",
    "* I love doctest\n",
    "* I have only come across pytest in the last week\n",
    "* I have a PR which if accepted will add pytests to Rose. \n",
    "\n",
    "<span style=\"font-size:4em\">ðŸŒ¹</span>\n",
    "\n",
    "<span style='color:red; font-size:1.2em'>I'm not an expert, but a fellow traveller sharing discoveries - I could be plain wrong, or raise points people disagree with!</span>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## What I found on the Web:\n",
    "I'm summarizing, doesn't mean arguments necessarily convince me...\n",
    "### The web says (In Favour):\n",
    "* Produces tidier code than unittest - no requirement to subclass unittest.TestCase [1] [2] [5]\n",
    "\n",
    "* Simpler to use because it uses `assert` rather than importing asserting functions.\n",
    "\n",
    "* Failure info is often easier to read [1]\n",
    "\n",
    "* Debugging is quite nice - it's possible to drop into debug mode if a test fails. [1] [5]\n",
    "\n",
    "* Still Runs Unittests and Doctests tests anyway.\n",
    "\n",
    "* Extensions/Plugins include support for Parallelization - really important on big projects! [4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### ... and against\n",
    "* Not making tests methods of a test class make it harder for test framework to decide what to run [3]\n",
    "\n",
    "* unittest derives from xUnit and so has cross language familiarity? [1]\n",
    "\n",
    "* Not available on RHEL6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Sources\n",
    "1. https://www.slant.co/versus/9148/9149/~unittest_vs_pytest\n",
    "2. https://docs.python-guide.org/writing/tests/\n",
    "3. https://cournape.github.io/why-i-am-not-a-fan-of-pytest.html - bit ranty?\n",
    "4. https://docs.python-guide.org/writing/tests/\n",
    "5. https://docs.pytest.org/en/latest/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Pytest - An example\n",
    "For the sake of illustrating the differences to myself I wrote some very simple code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# %load function.py\n",
    "\n",
    "def square_plus_10(x):\n",
    "    \"\"\"\n",
    "    Doctest Example (Including one designed to fail)\n",
    "    >>> square_plus_10(2)\n",
    "    14\n",
    "    >>> square_plus_10(-2)\n",
    "    14\n",
    "    >>> square_plus_10(7)\n",
    "    42\n",
    "    \"\"\"\n",
    "    return (x * x) + 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "I also wrote some unittests:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# %load tests_unittest/test_function1.py\n",
    "import unittest\n",
    "\n",
    "from function import square_plus_10\n",
    "\n",
    "# Very simple unittest\n",
    "class TestSquarePlus10(unittest.TestCase):\n",
    "    def test_basic_ok1(self):\n",
    "        self.assertEqual(square_plus_10(2), 14)\n",
    "\n",
    "    def test_basic_ok2(self):\n",
    "        self.assertEqual(square_plus_10(-2), 14)\n",
    "\n",
    "    def test_which_ought_to_fail(self):\n",
    "        self.assertEqual(square_plus_10(7), \"Bowl of petunias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..F\n",
      "======================================================================\n",
      "FAIL: test_which_ought_to_fail (tests_unittest.test_function1.TestSquarePlus10)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/net/home/h02/tpilling/external_share_notebooks/pytest/tests_unittest/test_function1.py\", line 21, in test_which_ought_to_fail\n",
      "    self.assertEqual(square_plus_10(7), \"Bowl of petunias\")\n",
      "AssertionError: 59 != 'Bowl of petunias'\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.001s\n",
      "\n",
      "FAILED (failures=1)\n"
     ]
    }
   ],
   "source": [
    "!python3 -m unittest tests_unittest/test_function1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What could this look like in pytest?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "exactly the same?!  - you can use Pytest on unittests!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTest session starts (platform: linux, Python 3.7.2, pytest 4.3.0, pytest-sugar 0.9.2)\u001b[0m\n",
      "rootdir: /net/home/h02/tpilling/external_share_notebooks/pytest, inifile:\n",
      "plugins: xdist-1.26.1, sugar-0.9.2, forked-1.0.2\n",
      "\u001b[1mcollecting ... \u001b[0m\n",
      " \u001b[36mtests_unittest/\u001b[0mtest_function1.py\u001b[0m \u001b[32mâœ“\u001b[0m\u001b[32mâœ“\u001b[0m                                                                                                                                                                 \u001b[32m67% \u001b[0m\u001b[40m\u001b[32mâ–ˆ\u001b[0m\u001b[40m\u001b[32mâ–ˆâ–ˆ\u001b[0m\u001b[40m\u001b[32mâ–ˆ\u001b[0m\u001b[40m\u001b[32mâ–ˆâ–ˆâ–‹   \u001b[0m\n",
      "\n",
      "â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€• TestSquarePlus10.test_which_ought_to_fail â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•\n",
      "\n",
      "self = <test_function1.TestSquarePlus10 testMethod=test_which_ought_to_fail>\n",
      "\n",
      "\u001b[1m    def test_which_ought_to_fail(self):\u001b[0m\n",
      "\u001b[1m>       self.assertEqual(square_plus_10(7), \"Bowl of petunias\")\u001b[0m\n",
      "\u001b[1m\u001b[31mE       AssertionError: 59 != 'Bowl of petunias'\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtests_unittest/test_function1.py\u001b[0m:21: AssertionError\n",
      "\n",
      " \u001b[36mtests_unittest/\u001b[0mtest_function1.py\u001b[0m \u001b[31mâ¨¯\u001b[0m                                                                                                                                                                 \u001b[31m100% \u001b[0m\u001b[40m\u001b[32mâ–ˆ\u001b[0m\u001b[40m\u001b[32mâ–ˆâ–ˆ\u001b[0m\u001b[40m\u001b[32mâ–ˆ\u001b[0m\u001b[40m\u001b[32mâ–ˆâ–ˆ\u001b[0m\u001b[40m\u001b[31mâ–ˆ\u001b[0m\u001b[40m\u001b[31mâ–ˆâ–ˆâ–ˆ\u001b[0m\n",
      "\n",
      "Results (0.13s):\n",
      "\u001b[32m       2 passed\u001b[0m\n",
      "\u001b[31m       1 failed\u001b[0m\n",
      "         - \u001b[36mtests_unittest\u001b[0m/test_function1.py\u001b[0m:20 \u001b[31mTestSquarePlus10.test_which_ought_to_fail\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest tests_unittest/test_function1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# %load tests_pytest/test_pytest_example1.py\n",
    "import pytest\n",
    "\n",
    "from function import square_plus_10\n",
    "\n",
    "def test_basic_ok1():\n",
    "    assert square_plus_10(2) == 14\n",
    "\n",
    "def test_basic_ok2():\n",
    "    assert square_plus_10(-2) == 14\n",
    "\n",
    "def test_blatently_going_to_fail():\n",
    "    assert square_plus_10(7) == \"Bowl of petunias\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTest session starts (platform: linux, Python 3.7.2, pytest 4.3.0, pytest-sugar 0.9.2)\u001b[0m\n",
      "rootdir: /net/home/h02/tpilling/external_share_notebooks/pytest, inifile:\n",
      "plugins: xdist-1.26.1, sugar-0.9.2, forked-1.0.2\n",
      "\u001b[1mcollecting ... \u001b[0m\n",
      " \u001b[36mtests_pytest/\u001b[0mtest_pytest_example1.py\u001b[0m \u001b[32mâœ“\u001b[0m\u001b[32mâœ“\u001b[0m                                                                                                                                                             \u001b[32m67% \u001b[0m\u001b[40m\u001b[32mâ–ˆ\u001b[0m\u001b[40m\u001b[32mâ–ˆâ–ˆ\u001b[0m\u001b[40m\u001b[32mâ–ˆ\u001b[0m\u001b[40m\u001b[32mâ–ˆâ–ˆâ–‹   \u001b[0m\n",
      "\n",
      "â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€• test_blatently_going_to_fail â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•\n",
      "\n",
      "\u001b[1m    def test_blatently_going_to_fail():\u001b[0m\n",
      "\u001b[1m>       assert square_plus_10(7) == \"Bowl of petunias\"\u001b[0m\n",
      "\u001b[1m\u001b[31mE       AssertionError: assert 59 == 'Bowl of petunias'\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +  where 59 = square_plus_10(7)\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtests_pytest/test_pytest_example1.py\u001b[0m:12: AssertionError\n",
      "\n",
      " \u001b[36mtests_pytest/\u001b[0mtest_pytest_example1.py\u001b[0m \u001b[31mâ¨¯\u001b[0m                                                                                                                                                             \u001b[31m100% \u001b[0m\u001b[40m\u001b[32mâ–ˆ\u001b[0m\u001b[40m\u001b[32mâ–ˆâ–ˆ\u001b[0m\u001b[40m\u001b[32mâ–ˆ\u001b[0m\u001b[40m\u001b[32mâ–ˆâ–ˆ\u001b[0m\u001b[40m\u001b[31mâ–ˆ\u001b[0m\u001b[40m\u001b[31mâ–ˆâ–ˆâ–ˆ\u001b[0m\n",
      "\n",
      "Results (0.11s):\n",
      "\u001b[32m       2 passed\u001b[0m\n",
      "\u001b[31m       1 failed\u001b[0m\n",
      "         - \u001b[36mtests_pytest\u001b[0m/test_pytest_example1.py\u001b[0m:11 \u001b[31mtest_blatently_going_to_fail\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest tests_pytest/test_pytest_example1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTest session starts (platform: linux, Python 3.7.2, pytest 4.3.0, pytest-sugar 0.9.2)\u001b[0m\n",
      "rootdir: /net/home/h02/tpilling/external_share_notebooks/pytest, inifile:\n",
      "plugins: xdist-1.26.1, sugar-0.9.2, forked-1.0.2\n",
      "\u001b[1mcollecting ... \u001b[0m\n",
      "\n",
      "â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€• [doctest] function.square_plus_10 â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•\n",
      "004 \n",
      "005     Doctest Example (Including one designed to fail)\n",
      "006     >>> square_plus_10(2)\n",
      "007     14\n",
      "008     >>> square_plus_10(-2)\n",
      "009     14\n",
      "010     >>> square_plus_10(7)\n",
      "Expected:\n",
      "    A very surprised sperm whale\n",
      "Got:\n",
      "    59\n",
      "\n",
      "\u001b[1m\u001b[31m/net/home/h02/tpilling/external_share_notebooks/pytest/function.py\u001b[0m:10: DocTestFailure\n",
      "\n",
      " \u001b[36m\u001b[0mfunction.py\u001b[0m \u001b[31mâ¨¯\u001b[0m                                                                                                                                                                                      \u001b[31m100% \u001b[0m\u001b[40m\u001b[31mâ–ˆ\u001b[0m\u001b[40m\u001b[31mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m\n",
      "\n",
      "Results (0.04s):\n",
      "\u001b[31m       1 failed\u001b[0m\n",
      "         - \u001b[36m\u001b[0mfunction.py\u001b[0m:4 \u001b[31m[doctest] function.square_plus_10\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest --doctest-modules function.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "| Unittest | Pytest |\n",
    "| - | - |\n",
    "|Subclassing unittest.Testcase |simple functions|\n",
    "|Nicely organised |you can still have classes!| \n",
    "|assert Functions |Native assert using Boolean operators|\n",
    "|Not doctest |can run doctest|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Parameterizing Tests\n",
    "When you want to test a lot of similar things there are some interesting possibilities..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Traditionally you could have done something like: \n",
    "(Note the need for a custome `msg` to assist debugging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# %load tests_unittest/test_function2.py\n",
    "import unittest\n",
    "\n",
    "from function import square_plus_10\n",
    "\n",
    "TEST_CASES = ([ 2, 14],\n",
    "              [-2, 14],\n",
    "              [ 7, \"Bowl of petunias\"])\n",
    "\n",
    "class TestSquarePlus10_iterative_but_unhelpful(unittest.TestCase):\n",
    "    def test_basic(self):\n",
    "        for case in TEST_CASES:\n",
    "            # create a useful error message\n",
    "            msg = f\"square_plus_10({case[0]}) != {case[1]}\"\n",
    "            self.assertEqual(square_plus_10(case[0]), case[1], msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F\n",
      "======================================================================\n",
      "FAIL: test_basic (tests_unittest.test_function2.TestSquarePlus10_iterative_but_unhelpful)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/net/home/h02/tpilling/external_share_notebooks/pytest/tests_unittest/test_function2.py\", line 14, in test_basic\n",
      "    self.assertEqual(square_plus_10(case[0]), case[1], msg)\n",
      "AssertionError: 59 != 'Bowl of petunias' : square_plus_10(7) != Bowl of petunias\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.001s\n",
      "\n",
      "FAILED (failures=1)\n"
     ]
    }
   ],
   "source": [
    "!python3 -m unittest tests_unittest/test_function2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "(Aside) Which is ok, although the Python > 3.4 idiom is nicer..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# %load tests_unittest/test_function3.py\n",
    "import unittest\n",
    "\n",
    "from function import square_plus_10\n",
    "\n",
    "TEST_CASES = ([ 2, 14],\n",
    "              [-2, 14],\n",
    "              [ 7, \"Bowl of petunias\"])\n",
    "\n",
    "class TestSquarePlus10_iterative_nicer(unittest.TestCase):\n",
    "    def test_basic(self):\n",
    "        for case in TEST_CASES:\n",
    "            with self.subTest(case):\n",
    "                self.assertEqual(square_plus_10(case[0]), case[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "(Note the label at the top right - really handy for debugging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "FAIL: test_basic (tests_unittest.test_function3.TestSquarePlus10_iterative_nicer) [[7, 'Bowl of petunias']]\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/net/home/h02/tpilling/external_share_notebooks/pytest/tests_unittest/test_function3.py\", line 13, in test_basic\n",
      "    self.assertEqual(square_plus_10(case[0]), case[1])\n",
      "AssertionError: 59 != 'Bowl of petunias'\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.011s\n",
      "\n",
      "FAILED (failures=1)\n"
     ]
    }
   ],
   "source": [
    "!python3 -m unittest tests_unittest/test_function3.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### But in Pytest we have a parameterization of tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# %load tests_pytest/test_pytest_example.py\n",
    "import pytest\n",
    "\n",
    "from function import square_plus_10\n",
    "\n",
    "TEST_CASES = ([ 2, 14],\n",
    "              [-2, 14],\n",
    "              [ 7, \"Bowl of petunias\"])\n",
    "\n",
    "@pytest.mark.parametrize(\"test_input, expected\", TEST_CASES)\n",
    "def test_pytest_with_parameterization(test_input, expected):\n",
    "    assert square_plus_10(test_input) == expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTest session starts (platform: linux, Python 3.7.2, pytest 4.3.0, pytest-sugar 0.9.2)\u001b[0m\n",
      "rootdir: /net/home/h02/tpilling/external_share_notebooks/pytest, inifile:\n",
      "plugins: xdist-1.26.1, sugar-0.9.2, forked-1.0.2\n",
      "\u001b[1mcollecting ... \u001b[0m\n",
      " \u001b[36mtests_pytest/\u001b[0mtest_pytest_example.py\u001b[0m \u001b[32mâœ“\u001b[0m\u001b[32mâœ“\u001b[0m                                                                                                                                                              \u001b[32m67% \u001b[0m\u001b[40m\u001b[32mâ–ˆ\u001b[0m\u001b[40m\u001b[32mâ–ˆâ–ˆ\u001b[0m\u001b[40m\u001b[32mâ–ˆ\u001b[0m\u001b[40m\u001b[32mâ–ˆâ–ˆâ–‹   \u001b[0m\n",
      "\n",
      "â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€• test_pytest_with_parameterization[7-Bowl of petunias] â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•\n",
      "\n",
      "test_input = 7, expected = 'Bowl of petunias'\n",
      "\n",
      "\u001b[1m    @pytest.mark.parametrize(\"test_input, expected\", TEST_CASES)\u001b[0m\n",
      "\u001b[1m    def test_pytest_with_parameterization(test_input, expected):\u001b[0m\n",
      "\u001b[1m>       assert square_plus_10(test_input) == expected\u001b[0m\n",
      "\u001b[1m\u001b[31mE       AssertionError: assert 59 == 'Bowl of petunias'\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +  where 59 = square_plus_10(7)\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtests_pytest/test_pytest_example.py\u001b[0m:11: AssertionError\n",
      "\n",
      " \u001b[36mtests_pytest/\u001b[0mtest_pytest_example.py\u001b[0m \u001b[31mâ¨¯\u001b[0m                                                                                                                                                              \u001b[31m100% \u001b[0m\u001b[40m\u001b[32mâ–ˆ\u001b[0m\u001b[40m\u001b[32mâ–ˆâ–ˆ\u001b[0m\u001b[40m\u001b[32mâ–ˆ\u001b[0m\u001b[40m\u001b[32mâ–ˆâ–ˆ\u001b[0m\u001b[40m\u001b[31mâ–ˆ\u001b[0m\u001b[40m\u001b[31mâ–ˆâ–ˆâ–ˆ\u001b[0m\n",
      "\n",
      "Results (0.13s):\n",
      "\u001b[32m       2 passed\u001b[0m\n",
      "\u001b[31m       1 failed\u001b[0m\n",
      "         - \u001b[36mtests_pytest\u001b[0m/test_pytest_example.py\u001b[0m:9 \u001b[31mtest_pytest_with_parameterization[7-Bowl of petunias]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest tests_pytest/test_pytest_example.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Python DeBug Compatibility\n",
    "You can drop into debug mode giving you a chance to poke around in the environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTest session starts (platform: linux, Python 3.7.2, pytest 4.3.0, pytest-sugar 0.9.2)\u001b[0m\n",
      "rootdir: /net/home/h02/tpilling/external_share_notebooks/pytest, inifile:\n",
      "plugins: xdist-1.26.1, sugar-0.9.2, forked-1.0.2\n",
      "\u001b[1mcollecting ... \u001b[0m\n",
      " \u001b[36mtests_pytest/\u001b[0mtest_pytest_example.py\u001b[0m \u001b[32mâœ“\u001b[0m\u001b[32mâœ“\u001b[0m                                                                                                                                                              \u001b[32m67% \u001b[0m\u001b[40m\u001b[32mâ–ˆ\u001b[0m\u001b[40m\u001b[32mâ–ˆâ–ˆ\u001b[0m\u001b[40m\u001b[32mâ–ˆ\u001b[0m\u001b[40m\u001b[32mâ–ˆâ–ˆâ–‹   \u001b[0m\n",
      "\n",
      "â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€• test_pytest_with_parameterization[7-Bowl of petunias] â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•\n",
      "\n",
      "test_input = 7, expected = 'Bowl of petunias'\n",
      "\n",
      "\u001b[1m    @pytest.mark.parametrize(\"test_input, expected\", TEST_CASES)\u001b[0m\n",
      "\u001b[1m    def test_pytest_with_parameterization(test_input, expected):\u001b[0m\n",
      "\u001b[1m>       assert square_plus_10(test_input) == expected\u001b[0m\n",
      "\u001b[1m\u001b[31mE       AssertionError: assert 59 == 'Bowl of petunias'\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +  where 59 = square_plus_10(7)\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtests_pytest/test_pytest_example.py\u001b[0m:11: AssertionError\n",
      "\n",
      "\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> traceback >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "\n",
      "test_input = 7, expected = 'Bowl of petunias'\n",
      "\n",
      "\u001b[1m    @pytest.mark.parametrize(\"test_input, expected\", TEST_CASES)\u001b[0m\n",
      "\u001b[1m    def test_pytest_with_parameterization(test_input, expected):\u001b[0m\n",
      "\u001b[1m>       assert square_plus_10(test_input) == expected\u001b[0m\n",
      "\u001b[1m\u001b[31mE       AssertionError: assert 59 == 'Bowl of petunias'\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +  where 59 = square_plus_10(7)\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtests_pytest/test_pytest_example.py\u001b[0m:11: AssertionError\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> entering PDB >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "> /net/home/h02/tpilling/external_share_notebooks/pytest/tests_pytest/test_pytest_example.py(11)test_pytest_with_parameterization()\n",
      "-> assert square_plus_10(test_input) == expected\n",
      "(Pdb) \n",
      "--KeyboardInterrupt--\n",
      "(Pdb) "
     ]
    }
   ],
   "source": [
    "!pytest tests_pytest/test_pytest_example.py --pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Running Subsets of Tests\n",
    "You can still run subsets of tests which can be organised by class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTest session starts (platform: linux, Python 3.7.2, pytest 4.3.0, pytest-sugar 0.9.2)\u001b[0m\n",
      "rootdir: /net/home/h02/tpilling/external_share_notebooks/pytest, inifile:\n",
      "plugins: xdist-1.26.1, sugar-0.9.2, forked-1.0.2\n",
      "\u001b[1mcollecting ... \u001b[0m\n",
      "\n",
      "â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€• TestSquarePlus10_iterative_nicer.test_basic â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•\n",
      "\n",
      "self = <test_function3.TestSquarePlus10_iterative_nicer testMethod=test_basic>\n",
      "\n",
      "\u001b[1m    def test_basic(self):\u001b[0m\n",
      "\u001b[1m        for case in TEST_CASES:\u001b[0m\n",
      "\u001b[1m            with self.subTest(case):\u001b[0m\n",
      "\u001b[1m>               self.assertEqual(square_plus_10(case[0]), case[1])\u001b[0m\n",
      "\u001b[1m\u001b[31mE               AssertionError: 59 != 'Bowl of petunias'\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtests_unittest/test_function3.py\u001b[0m:13: AssertionError\n",
      "\n",
      " \u001b[36mtests_unittest/\u001b[0mtest_function3.py\u001b[0m \u001b[31mâ¨¯\u001b[0m                                                                                                                                                                 \u001b[31m100% \u001b[0m\u001b[40m\u001b[31mâ–ˆ\u001b[0m\u001b[40m\u001b[31mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m\n",
      "\n",
      "Results (0.07s):\n",
      "\u001b[31m       1 failed\u001b[0m\n",
      "         - \u001b[36mtests_unittest\u001b[0m/test_function3.py\u001b[0m:10 \u001b[31mTestSquarePlus10_iterative_nicer.test_basic\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#                      test module file :: class (optional)               ::test (optional)\n",
    "!pytest tests_unittest/test_function3.py::TestSquarePlus10_iterative_nicer::test_basic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Pytest also allows you to select tests by name search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTest session starts (platform: linux, Python 3.7.2, pytest 4.3.0, pytest-sugar 0.9.2)\u001b[0m\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /net/home/h02/tpilling/external_share_notebooks/pytest, inifile:\n",
      "plugins: xdist-1.26.1, sugar-0.9.2, forked-1.0.2\n",
      "\u001b[1mcollecting ... \u001b[0m\n",
      " \u001b[36mtests_pytest/test_pytest_example_allgood.py\u001b[0m::test_pytest_almost_equal\u001b[0m \u001b[32mâœ“\u001b[0m                                                                                                                            \u001b[32m100% \u001b[0m\u001b[40m\u001b[32mâ–ˆ\u001b[0m\u001b[40m\u001b[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m\n",
      "\n",
      "Results (0.04s):\n",
      "\u001b[32m       1 passed\u001b[0m\n",
      "\u001b[33m       1 deselected\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest tests_pytest/test_pytest_example_allgood.py -k \"almost_equal\" --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTest session starts (platform: linux, Python 3.7.2, pytest 4.3.0, pytest-sugar 0.9.2)\u001b[0m\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /net/home/h02/tpilling/external_share_notebooks/pytest, inifile:\n",
      "plugins: xdist-1.26.1, sugar-0.9.2, forked-1.0.2\n",
      "\u001b[1mcollecting ... \u001b[0m\n",
      " \u001b[36mtests_pytest/test_pytest_example_allgood.py\u001b[0m::test_pure_pytest_example\u001b[0m \u001b[32mâœ“\u001b[0m                                                                                                                            \u001b[32m100% \u001b[0m\u001b[40m\u001b[32mâ–ˆ\u001b[0m\u001b[40m\u001b[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m\n",
      "\n",
      "Results (0.04s):\n",
      "\u001b[32m       1 passed\u001b[0m\n",
      "\u001b[33m       1 deselected\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest tests_pytest/test_pytest_example_allgood.py -k \"not almost_equal\"  --verbose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Subsetting tests using pytest.mark\n",
    "This effectively adds a tagging system to your tests:\n",
    "\n",
    "A small change to the pytests file allows us to tag tests\n",
    "```python\n",
    "@pytest.mark.pointless_tests\n",
    "def test_pytest_almost_equal():\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTest session starts (platform: linux, Python 3.7.2, pytest 4.3.0, pytest-sugar 0.9.2)\u001b[0m\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /net/home/h02/tpilling/external_share_notebooks/pytest, inifile:\n",
      "plugins: xdist-1.26.1, sugar-0.9.2, forked-1.0.2\n",
      "\u001b[1mcollecting ... \u001b[0m\n",
      " \u001b[36mtests_pytest/test_pytest_example_allgood.py\u001b[0m::test_pytest_almost_equal\u001b[0m \u001b[32mâœ“\u001b[0m                                                                                                                            \u001b[32m100% \u001b[0m\u001b[40m\u001b[32mâ–ˆ\u001b[0m\u001b[40m\u001b[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m\n",
      "\n",
      "Results (0.04s):\n",
      "\u001b[32m       1 passed\u001b[0m\n",
      "\u001b[33m       1 deselected\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest tests_pytest/test_pytest_example_allgood.py -m \"pointless_tests\"  --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTest session starts (platform: linux, Python 3.7.2, pytest 4.3.0, pytest-sugar 0.9.2)\u001b[0m\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /net/home/h02/tpilling/external_share_notebooks/pytest, inifile:\n",
      "plugins: xdist-1.26.1, sugar-0.9.2, forked-1.0.2\n",
      "\u001b[1mcollecting ... \u001b[0m\n",
      " \u001b[36mtests_pytest/test_pytest_example_allgood.py\u001b[0m::test_pure_pytest_example\u001b[0m \u001b[32mâœ“\u001b[0m                                                                                                                            \u001b[32m100% \u001b[0m\u001b[40m\u001b[32mâ–ˆ\u001b[0m\u001b[40m\u001b[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m\n",
      "\n",
      "Results (0.02s):\n",
      "\u001b[32m       1 passed\u001b[0m\n",
      "\u001b[33m       1 deselected\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest tests_pytest/test_pytest_example_allgood.py -m \"not pointless_tests\"  --verbose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "And, rather wonderfully:\n",
    "```python\n",
    "@pytest.mark.skip(\"Some Excuse\")\n",
    "...\n",
    "@pytest.mark.skipif(some>condition, \"Another Excuse\") # Default example - test Python version\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pydest Xdist -\n",
    "A plugin to allow you to use multiprocessor testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTest session starts (platform: linux, Python 3.7.2, pytest 4.3.0, pytest-sugar 0.9.2)\u001b[0m\n",
      "rootdir: /net/home/h02/tpilling/external_share_notebooks/pytest, inifile:\n",
      "plugins: xdist-1.26.1, sugar-0.9.2, forked-1.0.2\n",
      "gw0 [4]\u001b[0m\n",
      "\n",
      " \u001b[36mtests_pytest/\u001b[0mtest_parallel.py\u001b[0m \u001b[32mâœ“\u001b[0m\u001b[32mâœ“\u001b[0m\u001b[32mâœ“\u001b[0m\u001b[32mâœ“\u001b[0m                                                                                                                                                                 \u001b[32m100% \u001b[0m\u001b[40m\u001b[32mâ–ˆ\u001b[0m\u001b[40m\u001b[32mâ–ˆ\u001b[0m\u001b[40m\u001b[32mâ–ˆ\u001b[0m\u001b[40m\u001b[32mâ–ˆâ–ˆ\u001b[0m\u001b[40m\u001b[32mâ–ˆ\u001b[0m\u001b[40m\u001b[32mâ–ˆ\u001b[0m\u001b[40m\u001b[32mâ–ˆ\u001b[0m\u001b[40m\u001b[32mâ–ˆâ–ˆ\u001b[0m\n",
      "\n",
      "Results (19.23s):\n",
      "\u001b[32m       4 passed\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest tests_pytest/test_parallel.py -n 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTest session starts (platform: linux, Python 3.7.2, pytest 4.3.0, pytest-sugar 0.9.2)\u001b[0m\n",
      "rootdir: /net/home/h02/tpilling/external_share_notebooks/pytest, inifile:\n",
      "plugins: xdist-1.26.1, sugar-0.9.2, forked-1.0.2\n",
      "gw0 [4] / gw1 [4] / gw2 [4] / gw3 [4]\u001b[0m\n",
      "\n",
      " \u001b[36mtests_pytest/\u001b[0mtest_parallel.py\u001b[0m \u001b[32mâœ“\u001b[0m\u001b[32mâœ“\u001b[0m\u001b[32mâœ“\u001b[0m\u001b[32mâœ“\u001b[0m                                                                                                                                                                 \u001b[32m100% \u001b[0m\u001b[40m\u001b[32mâ–ˆ\u001b[0m\u001b[40m\u001b[32mâ–ˆ\u001b[0m\u001b[40m\u001b[32mâ–ˆ\u001b[0m\u001b[40m\u001b[32mâ–ˆâ–ˆ\u001b[0m\u001b[40m\u001b[32mâ–ˆ\u001b[0m\u001b[40m\u001b[32mâ–ˆ\u001b[0m\u001b[40m\u001b[32mâ–ˆ\u001b[0m\u001b[40m\u001b[32mâ–ˆâ–ˆ\u001b[0m\n",
      "\n",
      "Results (6.15s):\n",
      "\u001b[32m       4 passed\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest tests_pytest/test_parallel.py -n 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Fixtures\n",
    "Fixtures are generator expressions which replace unittest set_up and tear_down methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# %load tests_pytest/test_fixtures_eg.py\n",
    "# Example of testing numpy functionality with a fixture\n",
    "# Since these are testing numpy f(n)'ality they are pointless\n",
    "import pytest\n",
    "import numpy\n",
    "from  colorama import Fore\n",
    "\n",
    "@pytest.fixture\n",
    "def numpy_wx_data():\n",
    "    print(Fore.RED + '\\n [NOTE] Setting Up')\n",
    "    import numpy\n",
    "    example = numpy.array([[10, 10, 10],\n",
    "                           [11, 12, 13],\n",
    "                           [10, 10, 10]])\n",
    "    yield example\n",
    "    print(Fore.BLUE + '\\n [NOTE] Tearing Down')\n",
    "    del example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def test_numpy_rot90(numpy_wx_data):\n",
    "    print(Fore.GREEN + ' [TEST] rot90')\n",
    "    result = numpy.rot90(numpy_wx_data)\n",
    "    expected = numpy.array([[10, 11, 10],\n",
    "                            [10, 12, 10],\n",
    "                            [10, 13, 10]])\n",
    "    assert result.all() == expected.all()\n",
    "\n",
    "def test_numpy_flip(numpy_wx_data):\n",
    "    print(Fore.GREEN + ' [TEST] flip')\n",
    "    result = numpy.flip(numpy_wx_data)\n",
    "    expected = numpy.array([[10, 10, 10],\n",
    "                            [13, 12, 11],\n",
    "                            [10, 10, 10]])\n",
    "    assert result.all() == expected.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTest session starts (platform: linux, Python 3.7.2, pytest 4.3.0, pytest-sugar 0.9.2)\u001b[0m\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /net/home/h02/tpilling/external_share_notebooks/pytest, inifile:\n",
      "plugins: xdist-1.26.1, sugar-0.9.2, forked-1.0.2\n",
      "\u001b[1mcollecting ... \u001b[0m\u001b[31m\n",
      " [NOTE] Setting Up\n",
      "\u001b[32m [TEST] rot90\n",
      "\n",
      "\u001b[34m\n",
      " [NOTE] Tearing Down\n",
      " \u001b[36mtests_pytest/test_fixtures_eg.py\u001b[0m::test_numpy_rot90\u001b[0m \u001b[32mâœ“\u001b[0m                                                                                                                                                \u001b[32m50% \u001b[0m\u001b[40m\u001b[32mâ–ˆ\u001b[0m\u001b[40m\u001b[32mâ–ˆâ–ˆâ–ˆâ–ˆ     \u001b[0m\u001b[31m\n",
      " [NOTE] Setting Up\n",
      "\u001b[32m [TEST] flip\n",
      "\n",
      "\u001b[34m\n",
      " [NOTE] Tearing Down\n",
      " \u001b[36mtests_pytest/test_fixtures_eg.py\u001b[0m::test_numpy_flip\u001b[0m \u001b[32mâœ“\u001b[0m                                                                                                                                                \u001b[32m100% \u001b[0m\u001b[40m\u001b[32mâ–ˆ\u001b[0m\u001b[40m\u001b[32mâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m\u001b[40m\u001b[32mâ–ˆ\u001b[0m\u001b[40m\u001b[32mâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m\n",
      "\n",
      "Results (0.60s):\n",
      "\u001b[32m       2 passed\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest tests_pytest/test_fixtures_eg.py --verbose --capture=no"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Conclusions\n",
    "I like the look of pytest because\n",
    "* It's easy to write simple tests\n",
    "* But scalable\n",
    "* It has neat tools for tagging and running subsets of tests\n",
    "* You can use a debugger on a failed test\n",
    "* Parameterize is nice\n",
    "* Paralellization is vital if you have a lot of tests\n",
    "* You can run doctest\n",
    "* Still runs unittest tests\n",
    "* Ecosystem of Plugins (My output is mostly prettified... by one)\n",
    "\n",
    "* I think that there is a whole other talk on the details of fixtures..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Discussion Point\n",
    "Should we aim to make our pytests unittest compatible, or not worry?\n",
    "\n",
    "## References\n",
    "* My source code at __https://github.com/wxtim/Notes/tree/master/pytest__ includes a list of references not in the the presentation\n",
    "* Mah spellin' __https://en.oxforddictionaries.com/spelling/ize-ise-or-yse__ so there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
